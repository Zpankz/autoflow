name: tidb-ai

services:
  redis:
    image: redis:latest
    restart: always
    volumes:
      - ./redis-data:/data
    command: ["redis-server", "--loglevel", "warning"]
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  backend:
    image: tidbai/backend:0.4.0
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:8000:80"
    env_file:
      - .env
    volumes:
      - ./data:/shared/data
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  frontend:
    image: tidbai/frontend:0.4.0
    restart: always
    depends_on:
      - backend
    ports:
      - "127.0.0.1:3000:3000"
    environment:
      BASE_URL: http://backend
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  background:
    image: tidbai/backend:0.4.0
    restart: always
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:5555:5555"
    env_file:
      - .env
    volumes:
      - ./data:/shared/data
    command: /usr/bin/supervisord
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "6"

  local-embedding-reranker:
    image: tidbai/local-embedding-reranker:v4-with-cache
    ports:
      - 5001:5001
    environment:
      - PRE_LOAD_DEFAULT_EMBEDDING_MODEL=true
      - PRE_LOAD_DEFAULT_RERANKER_MODEL=false
      - TRANSFORMERS_OFFLINE=1
    profiles:
      - local-embedding-reranker
